{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "194881ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8edb157",
   "metadata": {},
   "source": [
    "### covid data aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8990c701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_reported</th>\n",
       "      <th>Country</th>\n",
       "      <th>New_cases</th>\n",
       "      <th>Cumulative_cases</th>\n",
       "      <th>New_deaths</th>\n",
       "      <th>Cumulative_deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date_reported      Country  New_cases  Cumulative_cases  New_deaths  \\\n",
       "0    2020-01-03  Afghanistan          0                 0           0   \n",
       "1    2020-01-04  Afghanistan          0                 0           0   \n",
       "2    2020-01-05  Afghanistan          0                 0           0   \n",
       "3    2020-01-06  Afghanistan          0                 0           0   \n",
       "4    2020-01-07  Afghanistan          0                 0           0   \n",
       "\n",
       "   Cumulative_deaths  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import raw data\n",
    "covid = pd.read_csv('./data/WHO-COVID-19-global-data.csv')\n",
    "covid.drop(columns=['Country_code','WHO_region'], inplace=True)\n",
    "covid = covid[covid['Date_reported']<'2020-08-01']\n",
    "covid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a030e50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the weighted average as stated in the paper, pay attention to the country name in the origin data\n",
    "English_country = ['United States of America','The United Kingdom','Canada','Australia','South Africa','Ireland','New Zealand']\n",
    "English_dict={'United States of America':0.689,'The United Kingdom':0.161,'Canada':0.058,\\\n",
    "              'Australia':0.054,'South Africa':0.015, 'Ireland':0.012,'New Zealand':0.011}\n",
    "French_country = ['France','Canada','Cameroon','Belgium','Senegal','Benin','Switzerland']\n",
    "French_dict = {'France':0.629,'Canada':0.101,'Cameroon':0.092,'Belgium':0.079,'Senegal':0.043,\\\n",
    "               'Benin':0.038,'Switzerland':0.018}\n",
    "German_country = ['Germany','Austria','Switzerland']\n",
    "German_dict = {'Germany':0.87,'Austria':0.087,'Switzerland':0.063}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "293c1354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_sum(df, language):\n",
    "    res = np.zeros(4) # seven columns that we care\n",
    "    if language=='English':\n",
    "        for _, row in df.iterrows():\n",
    "            weight = English_dict[row['Country']]\n",
    "            res += weight*row[2:]\n",
    "        \n",
    "    elif language=='French':\n",
    "        for _, row in df.iterrows():\n",
    "            weight = French_dict[row['Country']]\n",
    "            res += weight*row[2:]\n",
    "        \n",
    "    elif language=='German':\n",
    "        for _, row in df.iterrows():\n",
    "            weight = German_dict[row['Country']]\n",
    "            res += weight*row[2:]\n",
    "    else:\n",
    "        print('Invalid language')\n",
    "        return\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9319777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# covid data integration\n",
    "English = covid[covid['Country'].isin(English_country)].groupby('Date_reported').apply(weight_sum, language='English')\n",
    "French = covid[covid['Country'].isin(French_country)].groupby('Date_reported').apply(weight_sum, language='French')\n",
    "German = covid[covid['Country'].isin(German_country)].groupby('Date_reported').apply(weight_sum, language='German')\n",
    "Japanese = covid[covid['Country'] == 'Japan'].set_index('Date_reported').drop(columns=['Country'])\n",
    "Italian = covid[covid['Country'] == 'Italy'].set_index('Date_reported').drop(columns=['Country'])\n",
    "Dutch = covid[covid['Country'] == 'Netherlands'].set_index('Date_reported').drop(columns=['Country'])\n",
    "Swedish = covid[covid['Country'] == 'Sweden'].set_index('Date_reported').drop(columns=['Country'])\n",
    "Korean = covid[covid['Country'] == 'Republic of Korea'].set_index('Date_reported').drop(columns=['Country'])\n",
    "Finnish = covid[covid['Country'] == 'Finland'].set_index('Date_reported').drop(columns=['Country'])\n",
    "Norwegian = covid[covid['Country'] == 'Norway'].set_index('Date_reported').drop(columns=['Country'])\n",
    "Danish = covid[covid['Country'] == 'Denmark'].set_index('Date_reported').drop(columns=['Country'])\n",
    "Serbian = covid[covid['Country'] == 'Serbia'].set_index('Date_reported').drop(columns=['Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43e20028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as a pickle file\n",
    "covid_agg = {\"en\":English, \"fr\":French, \"de\":German, \"ja\":Japanese, \"it\":Italian, \"nl\":Dutch, \"ko\":Korean,\\\n",
    "            \"no\":Norwegian, \"fi\":Finnish, \"sv\": Swedish, \"sr\":Serbian, \"da\":Danish}\n",
    "with open('./data/covid_agg_who.pickle', 'wb') as handle:\n",
    "    pickle.dump(covid_agg, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9ff951",
   "metadata": {},
   "source": [
    "### Google mobility data aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9ec3399",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jchen\\AppData\\Local\\Temp\\ipykernel_44068\\2133238311.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  google_mobility = pd.read_csv('./data/Global_Mobility_Report.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_region_code</th>\n",
       "      <th>country_region</th>\n",
       "      <th>sub_region_1</th>\n",
       "      <th>sub_region_2</th>\n",
       "      <th>metro_area</th>\n",
       "      <th>iso_3166_2_code</th>\n",
       "      <th>census_fips_code</th>\n",
       "      <th>retail_and_recreation_percent_change_from_baseline</th>\n",
       "      <th>grocery_and_pharmacy_percent_change_from_baseline</th>\n",
       "      <th>parks_percent_change_from_baseline</th>\n",
       "      <th>transit_stations_percent_change_from_baseline</th>\n",
       "      <th>workplaces_percent_change_from_baseline</th>\n",
       "      <th>residential_percent_change_from_baseline</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-15</th>\n",
       "      <td>AE</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-16</th>\n",
       "      <td>AE</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-17</th>\n",
       "      <td>AE</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-18</th>\n",
       "      <td>AE</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-19</th>\n",
       "      <td>AE</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           country_region_code        country_region sub_region_1  \\\n",
       "date                                                                \n",
       "2020-02-15                  AE  United Arab Emirates          NaN   \n",
       "2020-02-16                  AE  United Arab Emirates          NaN   \n",
       "2020-02-17                  AE  United Arab Emirates          NaN   \n",
       "2020-02-18                  AE  United Arab Emirates          NaN   \n",
       "2020-02-19                  AE  United Arab Emirates          NaN   \n",
       "\n",
       "           sub_region_2 metro_area iso_3166_2_code  census_fips_code  \\\n",
       "date                                                                   \n",
       "2020-02-15          NaN        NaN             NaN               NaN   \n",
       "2020-02-16          NaN        NaN             NaN               NaN   \n",
       "2020-02-17          NaN        NaN             NaN               NaN   \n",
       "2020-02-18          NaN        NaN             NaN               NaN   \n",
       "2020-02-19          NaN        NaN             NaN               NaN   \n",
       "\n",
       "            retail_and_recreation_percent_change_from_baseline  \\\n",
       "date                                                             \n",
       "2020-02-15                                                0.0    \n",
       "2020-02-16                                                1.0    \n",
       "2020-02-17                                               -1.0    \n",
       "2020-02-18                                               -2.0    \n",
       "2020-02-19                                               -2.0    \n",
       "\n",
       "            grocery_and_pharmacy_percent_change_from_baseline  \\\n",
       "date                                                            \n",
       "2020-02-15                                                4.0   \n",
       "2020-02-16                                                4.0   \n",
       "2020-02-17                                                1.0   \n",
       "2020-02-18                                                1.0   \n",
       "2020-02-19                                                0.0   \n",
       "\n",
       "            parks_percent_change_from_baseline  \\\n",
       "date                                             \n",
       "2020-02-15                                 5.0   \n",
       "2020-02-16                                 4.0   \n",
       "2020-02-17                                 5.0   \n",
       "2020-02-18                                 5.0   \n",
       "2020-02-19                                 4.0   \n",
       "\n",
       "            transit_stations_percent_change_from_baseline  \\\n",
       "date                                                        \n",
       "2020-02-15                                            0.0   \n",
       "2020-02-16                                            1.0   \n",
       "2020-02-17                                            1.0   \n",
       "2020-02-18                                            0.0   \n",
       "2020-02-19                                           -1.0   \n",
       "\n",
       "            workplaces_percent_change_from_baseline  \\\n",
       "date                                                  \n",
       "2020-02-15                                      2.0   \n",
       "2020-02-16                                      2.0   \n",
       "2020-02-17                                      2.0   \n",
       "2020-02-18                                      2.0   \n",
       "2020-02-19                                      2.0   \n",
       "\n",
       "            residential_percent_change_from_baseline  \n",
       "date                                                  \n",
       "2020-02-15                                       1.0  \n",
       "2020-02-16                                       1.0  \n",
       "2020-02-17                                       1.0  \n",
       "2020-02-18                                       1.0  \n",
       "2020-02-19                                       1.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Also need to do data integration for mobility\n",
    "google_mobility = pd.read_csv('./data/Global_Mobility_Report.csv')\n",
    "google_mobility.set_index('date', inplace=True)\n",
    "google_mobility = google_mobility[google_mobility['sub_region_1'].isna()]\n",
    "google_mobility.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7623f073",
   "metadata": {},
   "outputs": [],
   "source": [
    "English_country = ['United States','United Kingdom','Canada','Australia','South Africa','Ireland','New Zealand']\n",
    "English_dict={'United States':0.689,'United Kingdom':0.161,'Canada':0.058,\\\n",
    "              'Australia':0.054,'South Africa':0.015, 'Ireland':0.012,'New Zealand':0.011}\n",
    "French_country = ['France','Canada','Cameroon','Belgium','Senegal','Benin','Switzerland']\n",
    "French_dict = {'France':0.629,'Canada':0.101,'Cameroon':0.092,'Belgium':0.079,'Senegal':0.043,\\\n",
    "               'Benin':0.038,'Switzerland':0.018}\n",
    "German_country = ['Germany','Austria','Switzerland']\n",
    "German_dict = {'Germany':0.87,'Austria':0.087,'Switzerland':0.063}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31fd4225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_sum_mob(df, language):\n",
    "    res = np.zeros(6) # seven columns that we care\n",
    "    if language=='English':\n",
    "        for _, row in df.iterrows():\n",
    "            weight = English_dict[row['country_region']]\n",
    "            res += weight*row[7:]\n",
    "        \n",
    "    elif language=='French':\n",
    "        for _, row in df.iterrows():\n",
    "            weight = French_dict[row['country_region']]\n",
    "            res += weight*row[7:]\n",
    "        \n",
    "    elif language=='German':\n",
    "        for _, row in df.iterrows():\n",
    "            weight = German_dict[row['country_region']]\n",
    "            res += weight*row[7:]\n",
    "    else:\n",
    "        print('Invalid language')\n",
    "        return\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a06a1dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data integration\n",
    "English = google_mobility[google_mobility['country_region'].isin(English_country)].groupby('date').apply(weight_sum_mob, language='English')\n",
    "French = google_mobility[google_mobility['country_region'].isin(French_country)].groupby('date').apply(weight_sum_mob, language='French')\n",
    "German = google_mobility[google_mobility['country_region'].isin(German_country)].groupby('date').apply(weight_sum_mob, language='German')\n",
    "Japanese = google_mobility[google_mobility['country_region'] == 'Japan'].iloc[:,7:]\n",
    "Italian = google_mobility[google_mobility['country_region'] == 'Italy'].iloc[:,7:]\n",
    "Dutch = google_mobility[google_mobility['country_region'] == 'Netherlands'].iloc[:,7:]\n",
    "Swedish = google_mobility[google_mobility['country_region'] == 'Sweden'].iloc[:,7:]\n",
    "Korean = google_mobility[google_mobility['country_region'] == 'South Korea'].iloc[:,7:]\n",
    "Finnish = google_mobility[google_mobility['country_region'] == 'Finland'].iloc[:,7:]\n",
    "Norwegian = google_mobility[google_mobility['country_region'] == 'Norway'].iloc[:,7:]\n",
    "Danish = google_mobility[google_mobility['country_region'] == 'Denmark'].iloc[:,7:]\n",
    "Serbian = google_mobility[google_mobility['country_region'] == 'Serbia'].iloc[:,7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eedd0149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as a pickle file\n",
    "mobility_agg = {\"en\":English, \"fr\":French, \"de\":German, \"ja\":Japanese, \"it\":Italian, \"nl\":Dutch, \"ko\":Korean,\\\n",
    "            \"no\":Norwegian, \"fi\":Finnish, \"sv\": Swedish, \"sr\":Serbian, \"da\":Danish}\n",
    "with open('./data/mobility_agg.pickle', 'wb') as handle:\n",
    "    pickle.dump(mobility_agg, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d49d043",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
